model:
  vocab_size: 250002
  max_seq_len: 128
  hidden_dim: 768
  num_layers: 12
  num_heads: 12
  ff_dim: 3072
  dropout: 0.05
  embedding_cond_dim: 1024
  mask_token_id: 250001

training:
  batch_size: 200
  grad_accum: 8
  max_steps: 200000
  lr: 0.0003125
  min_lr_ratio: 0.1
  weight_decay: 0.01
  warmup_steps: 3000
  max_grad_norm: 1.0
  log_every: 1
  eval_every: 500
  num_workers: 4
  mixed_precision: true
  ema_decay: 0.9999

data:
  data_dir: data_v2
  val_split: 0.01

evaluation:
  num_denoise_steps: 50
  num_samples: 1000
  jina_model: jinaai/jina-embeddings-v3
